# =============================================================================
# Configuration du système RAG Mathématiques (.env.example)
# =============================================================================

# ----- Runtime -----
# local | cloud | hybrid   (hybrid = cloud en primaire si dispo, local en fallback)
RUNTIME_MODE=hybrid

# ----- Chunking -----
MATH_CHUNK_SIZE=1000
MATH_CHUNK_OVERLAP=150

# ----- Chemins -----
MATH_PDF_PATH=./model/livre_2011.pdf
MATH_DB_DIR=./db/chroma_db_math_v3_1
MATH_COLLECTION_NAME=math_course_v3_1

# ----- Ollama endpoints -----
# Hôte local (fallback si pas de cloud ou en mode local)
# NB: le code lit d'abord OLLAMA_HOST (legacy), puis OLLAMA_LOCAL_HOST.
# Si tu utilises uniquement le local, définir OLLAMA_LOCAL_HOST suffit.
OLLAMA_LOCAL_HOST=http://localhost:11434

# Hôte cloud (requis si RUNTIME_MODE=cloud ou hybrid sans local)
# OLLAMA_CLOUD_HOST=https://ollama.your-domain.tld # Exemple: https://ollama.com
# OLLAMA_API_KEY=your_ollama_cloud_api_key

# ----- Modèles LLM -----
# Modèle primaire côté local
MATH_LLM_LOCAL=qwen2.5:7b-math
# Modèle primaire côté cloud
MATH_LLM_CLOUD=deepseek-v3.1:671b-cloud

# ----- Rewriter (réécriture de requêtes) -----
MATH_USE_REWRITER=1
MATH_LLM_REWRITER_LOCAL=gemma3:4b
MATH_LLM_REWRITER_CLOUD=glm-4.6:cloud

# ----- Embeddings -----
EMBED_PRIMARY_MODEL_NAME=bge-m3:latest
EMBED_ALT_MODEL_NAME=mxbai-embed-large:latest

# ----- Reranker (CrossEncoder) -----
MATH_USE_RERANKER=1
# Accepte "bge-reranker-v2-m3:latest" (mappé en BAAI/bge-reranker-v2-m3) ou un ID HF direct.
MATH_RERANKER_MODEL=bona/bge-reranker-v2-m3:latest
# Tuning perf (optionnel) : "cpu" | "cuda" | "mps"
# RERANKER_DEVICE=cpu
# RERANK_MAX_LEN=256
# RERANK_BATCH=16

# ----- Router — seuils -----
ROUTER_RAG_FIRST=0.55
ROUTER_LLM_FIRST=0.35

# ----- Routeur — Poids (somme renormalisée automatiquement à 1.0) -----
# SIM   : similarité fuzzy entre question et documents
# STRUCT: bonus si les filtres (chapitre, bloc) concordent avec les docs
# KW    : petit boost si le texte ressemble à des maths (mots-clés/symboles)
# PIN   : boost si un contexte "épinglé" est actif (et petite synergie si on reste en RAG)
ROUTER_W_SIM=0.65
ROUTER_W_STRUCT=0.20
ROUTER_W_KW=0.075
ROUTER_W_PIN=0.075

# ----- Routeur — Pénalités si contexte faible -----
# Appliqué si RAG renvoie peu de hits (<3) OU si la similarité max < 0.25
ROUTER_WEAK_PENALTY=0.20
# Pénalité additionnelle si la question cible un chapitre/bloc précis mais que le contexte est faible
ROUTER_WEAK_PENALTY_FOCUS=0.10

# ----- Hybrid retrieval -----
# 1 = combine BM25 + vecteur même si la base vectorielle est dispo ; 0 = vecteur seul
USE_BM25_WITH_VECTOR=0

# ----- Serveur FastAPI (si tu exposes une API) -----
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
SERVER_RELOAD=true
