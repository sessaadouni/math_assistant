# ğŸ“ Assistant MathÃ©matiques RAG v3.1 - RefactorÃ©

SystÃ¨me RAG (Retrieval-Augmented Generation) pour l'assistance en mathÃ©matiques, avec architecture modulaire, CLI moderne et API FastAPI.

## âœ¨ NouveautÃ©s v3.1

- âœ… **Architecture modulaire** : Code organisÃ© en modules rÃ©utilisables
- âœ… **Configuration centralisÃ©e** : Gestion propre via dataclasses et `.env`
- âœ… **CLI amÃ©liorÃ©** : Interface Rich moderne avec thÃ¨me GitHub Dark
- âœ… **API FastAPI** : Serveur avec endpoints dÃ©diÃ©s (chat, fiches, examens...)
- âœ… **Reranker intÃ©grÃ©** : CrossEncoder pour amÃ©liorer la qualitÃ© du retrieval
- âœ… **Query rewriting** : RÃ©Ã©criture intelligente des requÃªtes de suivi
- âœ… **MÃ©moire de session** : Contexte persistant avec pin/unpin
- âœ… **Routage canonique** : Gestion spÃ©cifique de requÃªtes (ex: Leibniz)

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ README_REFACTORED.md          # Ce fichier
â”œâ”€â”€ .env.example                  # Configuration exemple
â”œâ”€â”€ pyproject.toml                # DÃ©pendances (uv/pip)
â”œâ”€â”€ server.py                     # Serveur FastAPI
â”‚
â”œâ”€â”€ src/                          # Code source refactorisÃ©
â”‚   â”œâ”€â”€ core/                     # CÅ“ur du systÃ¨me
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration centralisÃ©e
â”‚   â”‚   â””â”€â”€ rag_engine.py         # Moteur RAG
â”‚   â”‚
â”‚   â”œâ”€â”€ assistant/                # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ assistant.py          # Assistant principal
â”‚   â”‚   â””â”€â”€ prompts.py            # Templates de prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ controllers/              # ContrÃ´leurs API
â”‚   â”‚   â””â”€â”€ math_assistant_controller.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Utilitaires
â”‚   â”‚   â”œâ”€â”€ ollama.py             # Client Ollama
â”‚   â”‚   â””â”€â”€ text_processing.py   # Traitement texte/LaTeX
â”‚   â”‚
â”‚   â””â”€â”€ ui/                       # Interfaces utilisateur
â”‚       â”œâ”€â”€ cli/                  # Interface CLI
â”‚       â”‚   â”œâ”€â”€ app.py            # Application CLI
â”‚       â”‚   â””â”€â”€ styles.py         # Styles Rich
â”‚       â””â”€â”€ gui/                  # Interface GUI (WIP)
â”‚
â”œâ”€â”€ scripts/                      # Scripts de lancement
â”‚   â”œâ”€â”€ run_cli.py                # Lancer CLI
â”‚   â”œâ”€â”€ run_gui.py                # Lancer GUI
â”‚   â”œâ”€â”€ gen_sft_qa.py             # GÃ©nÃ©ration donnÃ©es SFT
â”‚   â””â”€â”€ train_reranker.py         # EntraÃ®nement reranker
â”‚
â”œâ”€â”€ before/                       # Code legacy (rÃ©fÃ©rence)
â”‚   â”œâ”€â”€ math_assistant_cli.py
â”‚   â”œâ”€â”€ math_assistant_gui.py
â”‚   â””â”€â”€ model/
â”‚
â”œâ”€â”€ data/                         # DonnÃ©es
â”œâ”€â”€ db/                           # Base vectorielle Chroma
â””â”€â”€ model/                        # ModÃ¨les et PDFs
    â””â”€â”€ livre_2011.pdf
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10+
- Ollama (local ou compte cloud)
- [uv](https://github.com/astral-sh/uv) (recommandÃ©) ou pip

### Ã‰tapes

```bash
# 1. Cloner le repo
git clone <url>
cd test_ollama_rag/server

# 2. Installer les dÃ©pendances
uv sync
# ou avec pip:
# pip install -e .

# 3. Configurer l'environnement
cp .env.example .env
# Ã‰diter .env avec vos valeurs

# 4. (Optionnel) Installer le reranker
pip install sentence-transformers

# 5. Indexer le PDF (premiÃ¨re fois uniquement)
python -m src.core.rag_engine
```

---

## ğŸ’» Utilisation

### CLI

```bash
# Lancer le CLI
python scripts/run_cli.py

# ou directement
uv run src.ui.cli.app
```

**Commandes principales :**

```
# Questions simples
Quelle est la dÃ©finition d'un espace vectoriel ?

# Filtres rapides
/exercice application du thÃ©orÃ¨me de ThalÃ¨s
/mÃ©thode rÃ©solution d'Ã©quations diffÃ©rentielles
/thÃ©orie thÃ©orÃ¨me de Bolzano-Weierstrass

# PortÃ©e (scope)
/scope set chapter=21 type=thÃ©orie
/ch 28
/bloc thÃ©orÃ¨me 28.7

# MÃ©moire
/pin                # Ã‰pingler le contexte
/unpin              # DÃ©sÃ©pingler
/forget             # Tout oublier
/new-chat           # Nouveau chat isolÃ©

# Autres
/link on            # Activer auto-link follow-up
/debug on           # Mode debug
/log save           # Sauvegarder en JSONL
q                   # Quitter
```

### API FastAPI

```bash
# Lancer le serveur
python server.py

# ou avec uvicorn
uvicorn server:app --reload --host 0.0.0.0 --port 8000
```

**Endpoints disponibles :**

```
GET  /                     # Infos API
GET  /docs                 # Documentation Swagger
GET  /api/health           # Health check
GET  /api/rag_check        # Diagnostic RAG

# Questions & RÃ©ponses
GET  /api/chat?question=...&k=6&doc_type=exercice&chapter=21

# Fiches de rÃ©vision
GET  /api/sheet?topic=...&level=PrÃ©pa&chapter=21
POST /api/sheet_review     # VÃ©rifier une fiche

# Formules
GET  /api/formula?query=...

# Examens
GET  /api/exam?chapters=1,5,7&duration=3h&level=PrÃ©pa

# Cours complet
GET  /api/course?notion=...&level=PrÃ©pa

# Correction de copie
POST /api/grade
```

**Exemple avec curl :**

```bash
curl "http://localhost:8000/api/chat?question=thÃ©orÃ¨me%20de%20Leibniz&chapter=28"
```

### GUI (WIP)

```bash
python scripts/run_gui.py
```

_Note : Le GUI est en cours de refactoring. Pour l'instant, il utilise l'ancienne version._

---

## âš™ï¸ Configuration

Toutes les options sont dans `.env` :

```bash
# ModÃ¨les
MATH_LLM_NAME=deepseek-v3.1:671b-cloud
EMBED_MODEL_NAME=mxbai-embed-large:latest

# Chemins
MATH_PDF_PATH=./model/livre_2011.pdf
MATH_DB_DIR=./db/chroma_db_math_v3_1

# Features
MATH_USE_RERANKER=1           # 1=actif, 0=dÃ©sactivÃ©
MATH_REWRITE=1                # Query rewriting

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_API_KEY=                # Pour Ollama Cloud
```

---

## ğŸ—ï¸ Architecture

### Flux de traitement

```
Question utilisateur
    â†“
[Query Rewriter] â† Contexte session
    â†“
[Canonical Router] â† Routes prÃ©dÃ©finies
    â†“
[Hybrid Retriever] (BM25 + Vectoriel)
    â†“
[Reranker] (optionnel)
    â†“
[LLM] + Context
    â†“
RÃ©ponse formatÃ©e
```

### Composants clÃ©s

- **RAGEngine** : Orchestration gÃ©nÃ©rale (loading, splitting, indexing, retrieval)
- **HybridRetriever** : Fusion BM25 + vectoriel + reranking
- **MathAssistant** : Logique mÃ©tier (mÃ©moire, routes, gÃ©nÃ©ration)
- **SessionMemory** : Gestion du contexte et de la portÃ©e
- **QueryRewriter** : RÃ©Ã©criture intelligente des requÃªtes

---

## ğŸ¨ Styles

### CLI (Rich)

- **ThÃ¨me** : GitHub Dark
- **Tableaux** : Bordures arrondies, lignes alternÃ©es
- **Panneaux** : ColorÃ©s par type (info/success/warning/error)
- **Markdown** : Support natif dans les rÃ©ponses

### GUI (Qt)

- **Palette** : GitHub Dark moderne
- **Composants** : States hover/pressed/disabled
- **KaTeX** : Rendu LaTeX via WebEngine
- **Scrollbars** : Custom, discrÃ¨tes

---

## ğŸ“Š FonctionnalitÃ©s avancÃ©es

### Auto-link & MÃ©moire

```bash
# Question initiale
> ThÃ©orÃ¨me de Leibniz pour le barycentre
[Contexte dÃ©tectÃ©: chapitre 28, thÃ©orÃ¨me 28.7]

# Question de suivi (auto-link activÃ©)
> Peux-tu me donner un exemple ?
# â†’ Cherche dans chapitre 28, thÃ©orÃ¨me 28.7 automatiquement

# Ã‰pingler le contexte
> /pin
# â†’ Toutes les questions suivantes utiliseront ce contexte

# DÃ©sÃ©pingler
> /unpin
```

### PortÃ©e (Scope)

```bash
# DÃ©finir une portÃ©e globale
> /scope set chapter=21 type=exercice
# â†’ Toutes les recherches filtrent sur chapitre 21, exercices

# Voir la portÃ©e
> /scope show

# RÃ©initialiser
> /scope clear
```

### Routes canoniques

Gestion spÃ©cifique de requÃªtes ambiguÃ«s :

```python
"fonction de leibniz (barycentre)" â†’ chapitre 28, thÃ©orÃ¨me 28.7
"formule de leibniz (dÃ©rivÃ©es)" â†’ chapitre 12
```

Ajoutables dans `src/assistant/assistant.py : CanonicalRouter.ROUTES`

---

## ğŸ”§ DÃ©veloppement

### Ajouter un nouveau prompt

1. Ã‰diter `src/assistant/prompts.py`
2. CrÃ©er un template LangChain
3. Ajouter une fonction chain dans `src/controllers/math_assistant_controller.py`
4. CrÃ©er une route FastAPI

### Ajouter une commande CLI

1. Ã‰diter `src/ui/cli/app.py : MathCLI.handle_command()`
2. Ajouter la logique
3. Mettre Ã  jour l'aide dans `styles.py : CLIFormatter.command_help()`

### Tests

```bash
# Self-check du RAG
python -m src.core.rag_engine

# Test du serveur
python server.py
# Ouvrir http://localhost:8000/docs
```

---

## ğŸ› DÃ©pannage

### Erreur "PDF non trouvÃ©"

```bash
# VÃ©rifier le chemin dans .env
MATH_PDF_PATH=./model/livre_2011.pdf

# Ou mettre le chemin absolu
MATH_PDF_PATH=/home/user/projet/model/livre_2011.pdf
```

### Erreur "Model not found" (Ollama)

```bash
# Lister les modÃ¨les disponibles
ollama list

# Tirer un modÃ¨le
ollama pull deepseek-v3.1:671b-cloud
```

### Reranker lent

Le reranker amÃ©liore la qualitÃ© mais ralentit le retrieval (~1-2s).

```bash
# DÃ©sactiver dans .env
MATH_USE_RERANKER=0
```

### Base vectorielle corrompue

```bash
# Supprimer et rÃ©indexer
rm -rf db/chroma_db_math_v3_1
python -m src.core.rag_engine
```

---

## ğŸ“š Ressources

- [LangChain](https://python.langchain.com/)
- [Ollama](https://ollama.com/)
- [Chroma](https://www.trychroma.com/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Rich](https://rich.readthedocs.io/)
- [PySide6](https://doc.qt.io/qtforpython-6/)

---

## ğŸ“ TODO

- [ ] Refactoriser le GUI (PySide6)
- [ ] Ajouter tests unitaires
- [ ] Support multi-PDF
- [ ] Export rÃ©ponses en Markdown/LaTeX
- [ ] Historique de conversation persistant
- [ ] Interface web (Streamlit/Gradio)
- [ ] Fine-tuning du reranker sur donnÃ©es cours

---

## ğŸ“„ Licence

Projet personnel / AcadÃ©mique

---

## ğŸ‘¤ Auteur

Refactoring par Claude AI Assistant & Utilisateur

---

## ğŸ™ Remerciements

- Anthropic pour Claude
- CommunautÃ© LangChain
- Ã‰quipe Ollama